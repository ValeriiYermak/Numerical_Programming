{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "2Tdb3KJZ8ODE"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Douwload the data set of iris\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "feature_names = iris.feature_names\n",
        "class_names = iris.target_names\n",
        "\n",
        "print('Features:', feature_names)\n",
        "print('Classes:', class_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7wXyq-N8mFk",
        "outputId": "0eeab07a-7086-4296-819a-4ff4c241d7ac"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features: ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
            "Classes: ['setosa' 'versicolor' 'virginica']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and test data\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "print('\\nThe size of train set:', X_train.shape)\n",
        "print('The size of test set:', X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fBB22sDg-m8G",
        "outputId": "a91469ea-ed96-4ed3-ad94-37880b8e637c"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "The size of train set: (105, 4)\n",
            "The size of test set: (45, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature selection separately for each class\n",
        "classes = np.unique(y_train)\n",
        "n_classes = len (classes)\n",
        "n_features = X_train.shape[1]\n",
        "\n",
        "#Split the data on classes\n",
        "X_by_class = [X_train[y_train == c] for c in classes]"
      ],
      "metadata": {
        "id": "uFICpsYx_iTp"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate covariance matrices for each class\n",
        "cov_matrices = [np.cov(X_by_class[c].T) for c in range(n_classes)]\n",
        "print('\\nMatrices covariance for each clas:')\n",
        "for i, cov in enumerate(cov_matrices):\n",
        "    print(f'\\nClass {class_names[i]}:')\n",
        "    print(cov)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dAGBalhAeyw",
        "outputId": "99c072d7-2743-4a7e-bd1c-58797c655921"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Matrices covariance for each clas:\n",
            "\n",
            "Class setosa:\n",
            "[[0.11569892 0.09817204 0.01669892 0.00677419]\n",
            " [0.09817204 0.14113978 0.01950538 0.00712903]\n",
            " [0.01669892 0.01950538 0.03436559 0.00877419]\n",
            " [0.00677419 0.00712903 0.00877419 0.01191398]]\n",
            "\n",
            "Class versicolor:\n",
            "[[0.28297297 0.08816817 0.19847598 0.05760511]\n",
            " [0.08816817 0.08966967 0.09222973 0.04215465]\n",
            " [0.19847598 0.09222973 0.24599099 0.08385886]\n",
            " [0.05760511 0.04215465 0.08385886 0.04249249]]\n",
            "\n",
            "Class virginica:\n",
            "[[0.43414414 0.09777027 0.31913664 0.04939189]\n",
            " [0.09777027 0.09897898 0.08758258 0.06146396]\n",
            " [0.31913664 0.08758258 0.29644144 0.05224474]\n",
            " [0.04939189 0.06146396 0.05224474 0.0883033 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculation inverse covariance matrices\n",
        "inv_cov_matrices = [np.linalg.inv(cov) for cov in cov_matrices]"
      ],
      "metadata": {
        "id": "cG_3u1sWSz2Z"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculation the prior probabilities of each class\n",
        "priors = [np.mean(y_train == c) for c in classes]"
      ],
      "metadata": {
        "id": "N0b9PHvYTcOl"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#The function to calculate discriminant function for a single row\n",
        "def quadratic_discriminant_function(x, mean, inv_cov, prior, class_name):\n",
        "  diff = x - mean\n",
        "  # quadratic form:-1/2 * (x-μ)^T * Σ^-1 * (x-μ)\n",
        "  quadratic = -0.5 * np.dot(np.dot(diff.T, inv_cov), diff)\n",
        "  # The logarithm of the prior probabilities and determinant of the covariant matrice\n",
        "  log_term = np.log(prior) - 0.5 * np.log(np.linalg.det(np.linalg.inv(inv_cov)))\n",
        "  return quadratic + log_term"
      ],
      "metadata": {
        "id": "lHSoJs2CUVd3"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The function to calculate discriminant functions and probabilities for entire matrix\n",
        "def predict_proba_custom(X_test, means, inv_covs, priors):\n",
        "    n_samples = X_test.shape[0]\n",
        "    n_classes = len(priors)\n",
        "\n",
        "  # Calculate values of discriminant function for each class\n",
        "    discriminant_values = np.zeros((n_samples, n_classes))\n",
        "\n",
        "    for i in range(n_samples):\n",
        "          for c in range(n_classes):\n",
        "              discriminant_values[i, c] = quadratic_discriminant_function(X_test[i], means[c], inv_covs[c], priors[c], class_names[c])\n",
        "\n",
        "  # Convert to probabilities using softmax\n",
        "    max_values = np.max(discriminant_values, axis=1, keepdims=True)\n",
        "    exp_values = np.exp(discriminant_values - max_values) # for numerical stability\n",
        "    proba = exp_values / np.sum(exp_values, axis = 1, keepdims = True)\n",
        "    return proba\n",
        "\n",
        "# calculate average values for each class\n",
        "means = [np.mean(X_by_class[c], axis=0) for c in range(n_classes)]\n",
        "\n",
        "# predict of probabilities using our function\n",
        "proba_custom = predict_proba_custom(X_test, means, inv_cov_matrices, priors)\n",
        "predictions_custom = np.argmax(proba_custom, axis=1)"
      ],
      "metadata": {
        "id": "e0ip0HnNWOrR"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction using QuadraticDiscriminantAnalisys using sklearn\n",
        "qda = QuadraticDiscriminantAnalysis()\n",
        "qda.fit(X_train, y_train)\n",
        "proba_sklearn = qda.predict_proba(X_test)\n",
        "predictions_sklearn = qda.predict(X_test)\n"
      ],
      "metadata": {
        "id": "T3n-AE35Z5F3"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Comparison of results\n",
        "print(\"\\nComparison of results\")\n",
        "print('The accuracy of our implementation:', accuracy_score(y_test, predictions_custom))\n",
        "print(\"The accuracy sklearn QDA:\", accuracy_score(y_test, predictions_sklearn))\n",
        "\n",
        "print(\"\\nExample prediction probabilities:\")\n",
        "for i in range(5): #Output the first examples\n",
        "    print(f\"\\nThe example {i+1}:\")\n",
        "    print(\"Our implementation:\", proba_custom[i])\n",
        "    print('Sklearn: ', proba_sklearn[i])\n",
        "\n",
        "# Conclusion on the similarity of results\n",
        "print(\"\\nConclusion:\")\n",
        "print(\"Results of ours implementation QDA and implementation with sklearn very similar.\")\n",
        "print(\"The clasification accuracy is almost identical, confirming the correctness of our implementation\")\n",
        "print(\"Small differences in probabilities may be due to implementation specifics (e.g., handling of numerical stability).\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yN6aaMq3akRv",
        "outputId": "ca0b7977-fe72-41a4-d18f-4f264469f089"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Comparison of results\n",
            "The accuracy of our implementation: 1.0\n",
            "The accuracy sklearn QDA: 1.0\n",
            "\n",
            "Example prediction probabilities:\n",
            "\n",
            "The example 1:\n",
            "Our implementation: [1.09461742e-81 9.72753474e-01 2.72465259e-02]\n",
            "Sklearn:  [1.09461742e-81 9.72753474e-01 2.72465259e-02]\n",
            "\n",
            "The example 2:\n",
            "Our implementation: [1.00000000e+00 5.73230921e-28 3.05634855e-63]\n",
            "Sklearn:  [1.00000000e+00 5.73230921e-28 3.05634855e-63]\n",
            "\n",
            "The example 3:\n",
            "Our implementation: [2.43687730e-251 4.97846558e-009 9.99999995e-001]\n",
            "Sklearn:  [2.43687730e-251 4.97846558e-009 9.99999995e-001]\n",
            "\n",
            "The example 4:\n",
            "Our implementation: [5.10831398e-77 9.97298384e-01 2.70161647e-03]\n",
            "Sklearn:  [5.10831398e-77 9.97298384e-01 2.70161647e-03]\n",
            "\n",
            "The example 5:\n",
            "Our implementation: [1.26234369e-98 9.99396589e-01 6.03410624e-04]\n",
            "Sklearn:  [1.26234369e-98 9.99396589e-01 6.03410624e-04]\n",
            "\n",
            "Conclusion:\n",
            "Results of ours implementation QDA and implementation with sklearn very similar.\n",
            "The clasification accuracy is almost identical, confirming the correctness of our implementation\n",
            "Small differences in probabilities may be due to implementation specifics (e.g., handling of numerical stability).\n"
          ]
        }
      ]
    }
  ]
}